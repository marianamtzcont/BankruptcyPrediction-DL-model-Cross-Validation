{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90f8f2c",
   "metadata": {},
   "source": [
    "# *Bankruptcy prediction using a Deep learning model with Cross Validation*\n",
    "\n",
    "---------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af756a",
   "metadata": {},
   "source": [
    "The aim of a machine learning solution is to develop a model that can produce the desired output by analyzing a dataset created for a specific task. Binary classification problems are one of the most common. The idea is that the model developed looks at an input and predicts which of two possible classes it belongs to. Practical uses include sentiment analysis, spam detection, and cred-card fraud detection. Such models are trained with datasets labeled with 1s and 0s representing the two classes. \n",
    "\n",
    "In this exercise, we will see how we are going to classify the companies as being either in bankruptcy or not based on 64 features.\n",
    "To generate the Deep Learning model we will use the *Keras library*, which comes along with the *TensorFlow library*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647cb291",
   "metadata": {},
   "source": [
    "**1. Import libraries we will be using along the task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec11e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795189e",
   "metadata": {},
   "source": [
    "**2. Importing data**\n",
    "\n",
    "Import the dataset we will be working with  *Bancarrota.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa02a748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.379510</td>\n",
       "      <td>0.396410</td>\n",
       "      <td>2.047200</td>\n",
       "      <td>32.351000</td>\n",
       "      <td>0.388250</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>1.330500</td>\n",
       "      <td>1.138900</td>\n",
       "      <td>0.504940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121960</td>\n",
       "      <td>0.397180</td>\n",
       "      <td>0.878040</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>8.416000</td>\n",
       "      <td>5.137200</td>\n",
       "      <td>82.658000</td>\n",
       "      <td>4.415800</td>\n",
       "      <td>7.427700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.499880</td>\n",
       "      <td>0.472250</td>\n",
       "      <td>1.944700</td>\n",
       "      <td>14.786000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258340</td>\n",
       "      <td>0.996010</td>\n",
       "      <td>1.699600</td>\n",
       "      <td>0.497880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.420020</td>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.148600</td>\n",
       "      <td>3.273200</td>\n",
       "      <td>107.350000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>60.987000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248660</td>\n",
       "      <td>0.695920</td>\n",
       "      <td>0.267130</td>\n",
       "      <td>1.554800</td>\n",
       "      <td>-1.152300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309060</td>\n",
       "      <td>0.436950</td>\n",
       "      <td>1.309000</td>\n",
       "      <td>0.304080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241140</td>\n",
       "      <td>0.817740</td>\n",
       "      <td>0.765990</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>4.990900</td>\n",
       "      <td>3.951000</td>\n",
       "      <td>134.270000</td>\n",
       "      <td>2.718500</td>\n",
       "      <td>5.207800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081483</td>\n",
       "      <td>0.307340</td>\n",
       "      <td>0.458790</td>\n",
       "      <td>2.492800</td>\n",
       "      <td>51.952000</td>\n",
       "      <td>0.149880</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>1.866100</td>\n",
       "      <td>1.057100</td>\n",
       "      <td>0.573530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.142070</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.574600</td>\n",
       "      <td>3.614700</td>\n",
       "      <td>86.435000</td>\n",
       "      <td>4.222800</td>\n",
       "      <td>5.549700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.613230</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>1.406300</td>\n",
       "      <td>-7.312800</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>1.155900</td>\n",
       "      <td>0.386770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134850</td>\n",
       "      <td>0.484310</td>\n",
       "      <td>0.865150</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>6.398500</td>\n",
       "      <td>4.315800</td>\n",
       "      <td>127.210000</td>\n",
       "      <td>2.869200</td>\n",
       "      <td>7.898000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>-0.223515</td>\n",
       "      <td>0.387329</td>\n",
       "      <td>0.281804</td>\n",
       "      <td>2.017843</td>\n",
       "      <td>32.220480</td>\n",
       "      <td>-0.120310</td>\n",
       "      <td>-0.223515</td>\n",
       "      <td>2.042858</td>\n",
       "      <td>1.091357</td>\n",
       "      <td>0.612559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780296</td>\n",
       "      <td>-0.484320</td>\n",
       "      <td>1.137320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.485044</td>\n",
       "      <td>5.827173</td>\n",
       "      <td>120.608015</td>\n",
       "      <td>3.028686</td>\n",
       "      <td>5.222537</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>-0.071702</td>\n",
       "      <td>0.661316</td>\n",
       "      <td>0.178425</td>\n",
       "      <td>1.487297</td>\n",
       "      <td>-2.713831</td>\n",
       "      <td>-0.128223</td>\n",
       "      <td>-0.085766</td>\n",
       "      <td>0.577017</td>\n",
       "      <td>0.595145</td>\n",
       "      <td>0.338679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258542</td>\n",
       "      <td>-0.259774</td>\n",
       "      <td>0.795456</td>\n",
       "      <td>0.816270</td>\n",
       "      <td>3.758558</td>\n",
       "      <td>1.775902</td>\n",
       "      <td>232.725900</td>\n",
       "      <td>1.619469</td>\n",
       "      <td>1.511162</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>-0.154742</td>\n",
       "      <td>0.945439</td>\n",
       "      <td>-0.222230</td>\n",
       "      <td>0.772486</td>\n",
       "      <td>-80.120975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.159010</td>\n",
       "      <td>0.059298</td>\n",
       "      <td>2.852007</td>\n",
       "      <td>0.054563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038469</td>\n",
       "      <td>-6.678107</td>\n",
       "      <td>1.046342</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>10.592939</td>\n",
       "      <td>11.820948</td>\n",
       "      <td>128.577780</td>\n",
       "      <td>2.991096</td>\n",
       "      <td>12.467202</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>-0.158247</td>\n",
       "      <td>0.560193</td>\n",
       "      <td>-0.199368</td>\n",
       "      <td>0.526423</td>\n",
       "      <td>-52.815349</td>\n",
       "      <td>-0.056260</td>\n",
       "      <td>-0.158247</td>\n",
       "      <td>1.553115</td>\n",
       "      <td>1.621359</td>\n",
       "      <td>0.440380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.268260</td>\n",
       "      <td>0.948235</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>31.963896</td>\n",
       "      <td>14.670247</td>\n",
       "      <td>92.783481</td>\n",
       "      <td>4.963547</td>\n",
       "      <td>1.972845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>-0.153117</td>\n",
       "      <td>0.570028</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.911092</td>\n",
       "      <td>-21.925406</td>\n",
       "      <td>-0.013359</td>\n",
       "      <td>-0.152560</td>\n",
       "      <td>2.207511</td>\n",
       "      <td>3.624801</td>\n",
       "      <td>0.429993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180788</td>\n",
       "      <td>6.895249</td>\n",
       "      <td>1.058436</td>\n",
       "      <td>-1.349375</td>\n",
       "      <td>34.536284</td>\n",
       "      <td>27.422216</td>\n",
       "      <td>53.314105</td>\n",
       "      <td>6.960470</td>\n",
       "      <td>34.471132</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82628 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3        X4         X5        X6        X7  \\\n",
       "0      0.200550  0.379510  0.396410  2.047200  32.351000  0.388250  0.249760   \n",
       "1      0.209120  0.499880  0.472250  1.944700  14.786000  0.000000  0.258340   \n",
       "2      0.248660  0.695920  0.267130  1.554800  -1.152300  0.000000  0.309060   \n",
       "3      0.081483  0.307340  0.458790  2.492800  51.952000  0.149880  0.092704   \n",
       "4      0.187320  0.613230  0.229600  1.406300  -7.312800  0.187320  0.187320   \n",
       "...         ...       ...       ...       ...        ...       ...       ...   \n",
       "10995 -0.223515  0.387329  0.281804  2.017843  32.220480 -0.120310 -0.223515   \n",
       "10996 -0.071702  0.661316  0.178425  1.487297  -2.713831 -0.128223 -0.085766   \n",
       "10997 -0.154742  0.945439 -0.222230  0.772486 -80.120975  0.000000 -0.159010   \n",
       "10998 -0.158247  0.560193 -0.199368  0.526423 -52.815349 -0.056260 -0.158247   \n",
       "10999 -0.153117  0.570028  0.007631  0.911092 -21.925406 -0.013359 -0.152560   \n",
       "\n",
       "             X8        X9       X10  ...       X56       X57       X58  \\\n",
       "0      1.330500  1.138900  0.504940  ...  0.121960  0.397180  0.878040   \n",
       "1      0.996010  1.699600  0.497880  ...  0.121300  0.420020  0.853000   \n",
       "2      0.436950  1.309000  0.304080  ...  0.241140  0.817740  0.765990   \n",
       "3      1.866100  1.057100  0.573530  ...  0.054015  0.142070  0.945980   \n",
       "4      0.630700  1.155900  0.386770  ...  0.134850  0.484310  0.865150   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10995  2.042858  1.091357  0.612559  ... -0.780296 -0.484320  1.137320   \n",
       "10996  0.577017  0.595145  0.338679  ...  0.258542 -0.259774  0.795456   \n",
       "10997  0.059298  2.852007  0.054563  ... -0.038469 -6.678107  1.046342   \n",
       "10998  1.553115  1.621359  0.440380  ...  0.006837  0.268260  0.948235   \n",
       "10999  2.207511  3.624801  0.429993  ... -0.180788  6.895249  1.058436   \n",
       "\n",
       "            X59        X60        X61         X62       X63        X64    Y  \n",
       "0      0.001924   8.416000   5.137200   82.658000  4.415800   7.427700  0.0  \n",
       "1      0.000000   4.148600   3.273200  107.350000  3.400000  60.987000  0.0  \n",
       "2      0.694840   4.990900   3.951000  134.270000  2.718500   5.207800  0.0  \n",
       "3      0.000000   4.574600   3.614700   86.435000  4.222800   5.549700  0.0  \n",
       "4      0.124440   6.398500   4.315800  127.210000  2.869200   7.898000  0.0  \n",
       "...         ...        ...        ...         ...       ...        ...  ...  \n",
       "10995  0.000000  50.485044   5.827173  120.608015  3.028686   5.222537  1.0  \n",
       "10996  0.816270   3.758558   1.775902  232.725900  1.619469   1.511162  1.0  \n",
       "10997  0.005644  10.592939  11.820948  128.577780  2.991096  12.467202  1.0  \n",
       "10998  0.023060  31.963896  14.670247   92.783481  4.963547   1.972845  1.0  \n",
       "10999 -1.349375  34.536284  27.422216   53.314105  6.960470  34.471132  1.0  \n",
       "\n",
       "[82628 rows x 65 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Bancarrota.csv\",index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00597f",
   "metadata": {},
   "source": [
    "**3. Preparing data**\n",
    "\n",
    "The dataset imported needs pre-processing before it can be fed into the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedd9ae",
   "metadata": {},
   "source": [
    "- Get a Nympy representation of the DataFrame. \n",
    "\n",
    "To work with Keras and TensorFlow, we need to obtein a NumPy representation of the DataFrame. This can be achived by converting the data into a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ec5da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00550000e-01,  3.79510000e-01,  3.96410000e-01, ...,\n",
       "         4.41580000e+00,  7.42770000e+00,  0.00000000e+00],\n",
       "       [ 2.09120000e-01,  4.99880000e-01,  4.72250000e-01, ...,\n",
       "         3.40000000e+00,  6.09870000e+01,  0.00000000e+00],\n",
       "       [ 2.48660000e-01,  6.95920000e-01,  2.67130000e-01, ...,\n",
       "         2.71850000e+00,  5.20780000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-1.54741537e-01,  9.45439325e-01, -2.22229675e-01, ...,\n",
       "         2.99109598e+00,  1.24672020e+01,  1.00000000e+00],\n",
       "       [-1.58246751e-01,  5.60193357e-01, -1.99368492e-01, ...,\n",
       "         4.96354716e+00,  1.97284536e+00,  1.00000000e+00],\n",
       "       [-1.53117345e-01,  5.70027539e-01,  7.63101713e-03, ...,\n",
       "         6.96046981e+00,  3.44711321e+01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af5059",
   "metadata": {},
   "source": [
    "- Split the data into independent features (X) and dependent vector (Y)\n",
    "\n",
    "Define *X* Matrix by taking up all the data in the DataFrame apart from the last column, also create *Y* vector taking up the last column of the DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07082a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[:,0:64].astype(\"float\")\n",
    "y=dataset[:,64].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc2908",
   "metadata": {},
   "source": [
    "- Standardize features \n",
    "\n",
    "The StandarScaler() method is used to normalize, Scale or Standardize a feature by substracting the mean and then scaling the unit variance. Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29e59520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06400684, -0.05960982,  0.06766482, ..., -0.01039401,\n",
       "        -0.0436054 , -0.03007321],\n",
       "       [ 0.0662987 , -0.04335584,  0.07817856, ..., -0.01015003,\n",
       "        -0.05461308, -0.00381474],\n",
       "       [ 0.07687283, -0.01688387,  0.04974266, ..., -0.00988403,\n",
       "        -0.06199813, -0.03116156],\n",
       "       ...,\n",
       "       [-0.03100832,  0.01680959, -0.01809753, ..., -0.00994028,\n",
       "        -0.05904415, -0.0276025 ],\n",
       "       [-0.03194572, -0.03521151, -0.01492827, ..., -0.01029396,\n",
       "        -0.03766976, -0.03274756],\n",
       "       [-0.03057397, -0.03388357,  0.01376818, ..., -0.01068395,\n",
       "        -0.01603018, -0.01681465]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17291cf6",
   "metadata": {},
   "source": [
    "**4. Model creation and compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b41962",
   "metadata": {},
   "source": [
    "The built neural network consist of two layers with 128 and 64 nodes respectively, followed by one output node. The output layer utilizes the sigmoid activation function, which maps the input to a value between 0 and 1,representing a probability. This function compresses all values within the range of 0 and 1 into the shape of a sigmoid curve. The other two layers employ the ReLU (Rectified Linear Units) as the activation function. \n",
    "\n",
    "For compilation, the network utilizes the Adam optimizer, which is a momentum-based optimizer with a learning rate=0.1 and momentum=0.9. The chosen loos function is binary _crossentropy, specifically designed for binary classifiers. The metric used for evaluation is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cccfab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model:\n",
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=64,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "sgd=SGD(learning_rate=.01,momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b85ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a función that define the model, compiles it and returns it. \n",
    "def modelo_NN():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(128,input_dim=64,activation=\"relu\"))\n",
    "    model.add(Dense(64,activation=\"relu\"))\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    sgd=SGD(learning_rate=.01,momentum=0.9)\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "078d3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=modelo_NN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d259437d",
   "metadata": {},
   "source": [
    "**5. Model evaluation with Cross-Validation**\n",
    "\n",
    "Keras is a popular library for deep learning in Python, but the focus of the library is deep learning models. Focusing on only what you need to quickly and simply define and build deep learning models.The scikit-learn library in Python is built upon the SciPy stack for efficient numerical computation. It is a fully featured library for general machine learning and provides many useful utilities in developing deep learning models. There was a wrapper in the TensorFlow/Keras library to make deep learning models used as classification or regression estimators in scikit-learn. In this exercise we will focus in the KerasClassifier wrapper for a classification neural network created in Keras and used in the scikit-learn library.\n",
    "\n",
    "Cross-validation (CV) is a technique for evaluation a machine learning and testing its performance. The CV first divide the dataset into two parts: one for training, other for testing, then train the model on the training set,validate the model on the test set and Repeat these steps a couple of times. This number depends on the CV method used. There are plenty of CV techiques, we will use StratifiedK-fold from sklearn to perform 5-fold stratified cros-validation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9c310",
   "metadata": {},
   "source": [
    "- Pass the function that define the model to the KerasClassifier, also pass the arguments of epoch=12 and batch_size=32. These are automatically bundled up and passed on to the fit() function, which is called internally by the KerasClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbed9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=modelo_NN, epochs=12, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5ce6a",
   "metadata": {},
   "source": [
    "- Use the scikit-learn StratifiedKFold to perform 5-fold stratified cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f54ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f0037",
   "metadata": {},
   "source": [
    "- Use the scikit-learn function cross_val_score() to evaluate the model using the cross-validation scheme and print the results of the F1-scores for each fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fef6d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/517 [==============================] - 2s 3ms/step\n",
      "517/517 [==============================] - 1s 3ms/step\n",
      "517/517 [==============================] - 2s 3ms/step\n",
      "517/517 [==============================] - 1s 2ms/step\n",
      "517/517 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "f1_scores = cross_val_score(classifier, X_scaled, y, cv=skf, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d51c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-scores per fold:  [0.91638264 0.92032817 0.92376894 0.92475685 0.91996108]\n",
      "F1-score mean:  0.9210395339590715\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-scores per fold: \", f1_scores)\n",
    "print(\"F1-score mean: \", np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e64d46",
   "metadata": {},
   "source": [
    "The model achieves an F1-score of over 92%, indicating its high predictive performance. Further optimization can be explored by adjusting parameters such as the number of epochs, the layers, or the number of nodes per layer. However, the current score is already acceptable, and the model can be utilized for predictions on new datasets. Additionally, at the beginning, we can split the data and feed it into this trained model for predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
